{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats & Dogs\n",
    "\n",
    "\n",
    "This notebook serves as an exercise for learning the possibilities of **Transfer Learning** and to discover the differences between dataset size.\n",
    "\n",
    "This notebook was made by Group 8:\n",
    "- Lu√≠s Macedo, A80494\n",
    "- Carlos Castro, A81946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NCLASSES = 2\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "NUM_CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "DATA_SET_COUNT = 10000\n",
    "TEST_SET_COUNT = 2000\n",
    "TRAIN_SET_COUNT = (DATA_SET_COUNT) * 0.8\n",
    "VAL_SET_COUNT = (DATA_SET_COUNT) * 0.2\n",
    "DATA_SET_PATH=\"/kaggle/input/dogsVScats/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the **ResNet50** model from keras database [Keras](https://keras.io/applications/). It were used three arguments in the load:\n",
    "- **include_top**, that means if the top layers (fully connected) are to be included or not;\n",
    "- **weights**, the weights to be preloaded;\n",
    "- **input_shape**, the input shape.\n",
    "\n",
    "The **include_top** must be set to false for this exercise. The **weights** must be **none** or **'imagenet'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_shape=(HEIGHT, WIDTH, NUM_CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the following line of code is commented, the loaded model will not freeze the preloaded weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of the loaded model, we included the following layers:\n",
    "- Global Average Pooling 2D;\n",
    "- Dense, or fully connected, with 4096 nodes as output, using the **relu** activation function;\n",
    "- Dense, as the final layer, using the **sigmoid** activation function (outputs 0 or 1).\n",
    "\n",
    "Global Average Pooling (GAP) performs an average for each of the feature maps. Assuming the last conv layer is 3x3x256, we have 256 feature maps. Global average pooling is a layer with 256 values, each being the average of a feature map.\n",
    "\n",
    "For the last layer, we choose to use **sigmoid** because it's simpler than **softmax** for a binary answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         8392704     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4097        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 31,984,513\n",
      "Trainable params: 31,931,393\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(4096, activation='relu')(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "# x = layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model_3 = models.Model(inputs=base_model.input, outputs=x)\n",
    "print(model_3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset used is from the **Kaggle** competition [dogsVScats](https://www.kaggle.com/c/dogs-vs-cats/data).\n",
    "\n",
    "The organizations is as follow:\n",
    "- train/\n",
    "    - cat/\n",
    "    - dog/\n",
    "- test/\n",
    "    - cat/\n",
    "    - dog/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate dogs from cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_name(file_path):\n",
    "    return file_path.split(\".\")[0]\n",
    "\n",
    "train_photos = glob.glob(DATA_SET_PATH + \"train\" + os.path.sep + \"*.jpg\")\n",
    "    \n",
    "if os.path.isdir(DATA_SET_PATH + \"train\" + os.path.sep + \"cat\") == False:\n",
    "    os.mkdir(DATA_SET_PATH + \"train\" + os.path.sep + \"cat\")\n",
    "    \n",
    "if os.path.isdir(DATA_SET_PATH + \"train\" + os.path.sep + \"dog\") == False:\n",
    "    os.mkdir(DATA_SET_PATH + \"train\" + os.path.sep + \"dog\")\n",
    "\n",
    "for photo in train_photos:\n",
    "    photo_name = photo.split(os.path.sep)[-1]\n",
    "    os.replace(photo, DATA_SET_PATH + \"train\" + os.path.sep + get_label_name(photo_name) + os.path.sep + photo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DATA_SET_PATH + \"test\" + os.path.sep\n",
    "\n",
    "if os.path.isdir(path) == False:\n",
    "    os.mkdir(path)\n",
    "\n",
    "if os.path.isdir(path + \"cat\") == False:\n",
    "    os.mkdir(path + \"cat\")\n",
    "\n",
    "if os.path.isdir(path + \"dog\") == False:\n",
    "    os.mkdir(path + \"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking 1000 images from each class of train to the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DATA_SET_PATH + \"test\" + os.path.sep\n",
    "\n",
    "cats_test = glob.glob(path + \"cat\" + os.path.sep + \"*.jpg\")\n",
    "if len(cats_test) == 0:\n",
    "    cats = glob.glob(path + \"cat\" + os.path.sep + \"*.jpg\")\n",
    "    i=0\n",
    "    for cat in cats:\n",
    "        if i == 1000:\n",
    "            break\n",
    "        i+=1\n",
    "        cat_name = cat.split(os.path.sep)[-1]\n",
    "        os.replace(cat, path + \"cat\" + os.path.sep + cat_name)\n",
    "\n",
    "dogs_test = glob.glob(path + \"dog\" + os.path.sep + \"*.jpg\")\n",
    "if len(dogs_test) == 0:\n",
    "    dogs = glob.glob(path + \"dog\" + os.path.sep + \"*.jpg\")\n",
    "    i = 0\n",
    "    for dog in dogs:\n",
    "        if i == 1000:\n",
    "            break\n",
    "        i+=1\n",
    "        dog_name = dog.split(os.path.sep)[-1]\n",
    "        os.replace(dog, path + \"dog\" + os.path.sep + dog_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary function for loading the dataset\n",
    "Because **sigmoid** receives label with shape=(1), meaning that is a number. So, we dictated that 0 represent cats and 1 represent dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    if parts[-2]==\"cat\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [WIDTH, HEIGHT])\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "Replace the path with your own location of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = np.array(['cat', 'dog'])\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "listset = tf.data.Dataset.list_files(DATA_SET_PATH + \"split\" + DATA_SET_COUNT + \"/*/*.jpg\")\n",
    "dataset = listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "train_size = int(TRAIN_SET_COUNT)\n",
    "val_size = int(VAL_SET_COUNT)\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size = train_size)\n",
    "train_dataset = train_dataset.batch(batch_size=BATCH_SIZE)\n",
    "train_dataset = train_dataset.repeat();\n",
    "\n",
    "val_dataset = dataset.skip(train_size)\n",
    "val_dataset = val_dataset.batch(batch_size=BATCH_SIZE)\n",
    "val_dataset = val_dataset.repeat();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = tf.data.Dataset.list_files(DATA_SET_PATH + \"test/*/*.jpg\")\n",
    "testset = testset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "testset = testset.batch(batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a batch of images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    columns = 6\n",
    "    rows = BATCH_SIZE / columns + 1  \n",
    "    plt.figure(figsize=(10, 2 * rows))\n",
    "    for n in range(BATCH_SIZE):\n",
    "        ax = plt.subplot(rows, columns, n+1)\n",
    "        plt.imshow((image_batch[n]))\n",
    "        plt.title(classNames[label_batch[n]==1][0])\n",
    "        plt.axis('off')\n",
    "        \n",
    "        \n",
    "image_batch, label_batch = next(iter(train_dataset))  \n",
    "show_batch(image_batch, label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model for 20 epochs\n",
    "\n",
    "We used the **binary_crossentropy** as the loss function and a binary accuracy for more precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 250.0 steps, validate for 62.5 steps\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 112s 447ms/step - loss: 0.3673 - binary_accuracy: 0.8687 - val_loss: 0.7825 - val_binary_accuracy: 0.5094\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 78s 312ms/step - loss: 0.1745 - binary_accuracy: 0.9284 - val_loss: 0.9790 - val_binary_accuracy: 0.5064\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 77s 309ms/step - loss: 0.1454 - binary_accuracy: 0.9435 - val_loss: 0.6584 - val_binary_accuracy: 0.5516\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 76s 305ms/step - loss: 0.1281 - binary_accuracy: 0.9475 - val_loss: 0.5297 - val_binary_accuracy: 0.7445\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 78s 314ms/step - loss: 0.1083 - binary_accuracy: 0.9554 - val_loss: 0.3468 - val_binary_accuracy: 0.8075\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 78s 310ms/step - loss: 0.1048 - binary_accuracy: 0.9607 - val_loss: 0.8320 - val_binary_accuracy: 0.5734\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 76s 305ms/step - loss: 0.0891 - binary_accuracy: 0.9659 - val_loss: 0.1943 - val_binary_accuracy: 0.9236\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 74s 295ms/step - loss: 0.0909 - binary_accuracy: 0.9650 - val_loss: 0.2073 - val_binary_accuracy: 0.9251\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 0.0689 - binary_accuracy: 0.9732 - val_loss: 0.1218 - val_binary_accuracy: 0.9549\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 77s 307ms/step - loss: 0.0706 - binary_accuracy: 0.9736 - val_loss: 0.1970 - val_binary_accuracy: 0.9187\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 76s 303ms/step - loss: 0.0621 - binary_accuracy: 0.9750 - val_loss: 0.0982 - val_binary_accuracy: 0.9618\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 72s 289ms/step - loss: 0.0580 - binary_accuracy: 0.9774 - val_loss: 0.2532 - val_binary_accuracy: 0.9048\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 83s 333ms/step - loss: 0.0454 - binary_accuracy: 0.9837 - val_loss: 0.1252 - val_binary_accuracy: 0.9479\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 76s 305ms/step - loss: 0.0459 - binary_accuracy: 0.9843 - val_loss: 0.1302 - val_binary_accuracy: 0.9549\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 74s 294ms/step - loss: 0.0545 - binary_accuracy: 0.9801 - val_loss: 0.0643 - val_binary_accuracy: 0.9747\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 0.0625 - binary_accuracy: 0.9771 - val_loss: 0.1515 - val_binary_accuracy: 0.9385\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 77s 308ms/step - loss: 0.0362 - binary_accuracy: 0.9866 - val_loss: 0.1211 - val_binary_accuracy: 0.9509\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 76s 305ms/step - loss: 0.0387 - binary_accuracy: 0.9839 - val_loss: 0.2888 - val_binary_accuracy: 0.8760\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 72s 289ms/step - loss: 0.0361 - binary_accuracy: 0.9876 - val_loss: 0.0934 - val_binary_accuracy: 0.9628\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 82s 328ms/step - loss: 0.0469 - binary_accuracy: 0.9834 - val_loss: 0.0587 - val_binary_accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "# model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[ metrics.categorical_accuracy])\n",
    "# model_3 = models.Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=[metrics.binary_accuracy])\n",
    "history = model_3.fit(train_dataset, epochs=20, steps_per_epoch=train_size/BATCH_SIZE, validation_data = val_dataset, validation_steps= val_size/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show how the learning progressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "#plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model on the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 6s 90ms/step - loss: 0.2204 - binary_accuracy: 0.9400: 2s - loss: 0.2159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2203580503987651, 0.94]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "| Dataset size | Last Dense | weights  | Freeze | Accuracy |\n",
    "|--------------|------------|----------|--------|----------|\n",
    "| 250          | Softmax    | none     | no     | 0.503    |\n",
    "| 250          | Softmax    | imagenet | no     | 0.5      |\n",
    "| 250          | Softmax    | imagenet | yes    | 0.5      |\n",
    "|--------------|------------|----------|--------|----------|\n",
    "| 2500         | Softmax    | none     | no     | 0.579    |\n",
    "| 2500         | Softmax    | imagenet | no     | 0.799    |\n",
    "| 2500         | Softmax    | imagenet | yes    | 0.5      |\n",
    "|--------------|------------|----------|--------|----------|\n",
    "| 5000         | Softmax    | none     | no     | 0.7165   |\n",
    "| 5000         | Softmax    | imagenet | no     | 0.886    |\n",
    "| 5000         | Softmax    | imagenet | yes    | 0.473    |\n",
    "|--------------|------------|----------|--------|----------|\n",
    "| 10 000       | Softmax    | none     | no     | 0.746    |\n",
    "| 10 000       | Softmax    | imagenet | no     | 0.916    |\n",
    "| 10 000       | Softmax    | imagenet | yes    | 0.491    |\n",
    "|--------------|------------|----------|--------|----------|\n",
    "| 15 000       | Softmax    | none     | no     | 0.8545   |\n",
    "| 15 000       | Softmax    | imagenet | no     | 0.8765   |\n",
    "| 15 000       | Softmax    | imagenet | yes    | 0.5      |\n",
    "|--------------|------------|----------|--------|----------|\n",
    "| 10 000       | sigmoid    | none     | no     | 0.821    |\n",
    "| 10 000       | sigmoid    | imagenet | no     | 0.94     |\n",
    "| 10 000       | sigmoid    | imagenet | yes    | 0.496    |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The highest accuracy we get was: using **sigmoid** in the last Dense, training with 10 000 images, using the weights of **imagenet** without freezing the convolution weights.\n",
    "\n",
    "Through the analysis of the tests made, we concluded that using the preloaded weights without freezing the convolution weights get the best results, and as expected, the bigger the dataset, the better are the results, up to a limit. In other words, the accuracy increased with the increasement of the dataset, up to 10 000 images. We only tested a dataset with more images than 10 000, which had a worse accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
